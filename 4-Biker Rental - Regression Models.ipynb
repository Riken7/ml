{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3734b5a8-6a87-482f-8f49-97bb6a6a3a9d",
   "metadata": {},
   "source": [
    "# Predicting Bike Rental Usage Using Various Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182ea30a-fb95-4f84-bc1f-0ef5a400024f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- In this notebook, we aim to predict the total rental bike usage (`cnt`) using several regression models. We begin by identifying features that have a strong relationship with the target variable (`cnt`) using Pearson correlation. Then, we implement different regression models to predict `cnt` and evaluate their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc420ac-47e6-45d7-8f11-b25ab52f2645",
   "metadata": {},
   "source": [
    "## Step:1 Loading and Preparing the Dataset\n",
    "- **Dataset:** We use the `day.csv` dataset, which includes daily counts of rental bikes and various attributes.\n",
    "- **Dropping Columns:** The columns `registered` and `casual` are dropped since they are summed into the target variable `cnt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1892ea21-2e04-4e64-95c1-18ad540d45b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1        0        6           0   \n",
       "1        2  2011-01-02       1   0     1        0        0           0   \n",
       "2        3  2011-01-03       1   0     1        0        1           1   \n",
       "3        4  2011-01-04       1   0     1        0        2           1   \n",
       "4        5  2011-01-05       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed   cnt  \n",
       "0           2  0.344167  0.363625  0.805833   0.160446   985  \n",
       "1           2  0.363478  0.353739  0.696087   0.248539   801  \n",
       "2           1  0.196364  0.189405  0.437273   0.248309  1349  \n",
       "3           1  0.200000  0.212122  0.590435   0.160296  1562  \n",
       "4           1  0.226957  0.229270  0.436957   0.186900  1600  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"day.csv\")\n",
    "\n",
    "# Drop 'registered' and 'casual' from the DataFrame\n",
    "df = df.drop(['registered', 'casual'], axis=1)\n",
    "\n",
    "# Let's display the modiified data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b76ea63-5fd0-44ae-8881-005e1599a40a",
   "metadata": {},
   "source": [
    "## Step:2 Feature Selection Using Pearson Correlation\n",
    "- **Numerical Features:** We selected numerical features, including the target variable `cnt`.\n",
    "- **Correlation Threshold:** A threshold of `0.3` was used to identify features that are significantly correlated with `cnt`.\n",
    "- **Related Features:** Features with a Pearson correlation above the threshold were selected for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "604d8efb-d890-4d84-bf13-0253f3b9da39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation with cnt:\n",
      " instant       0.628830\n",
      "season        0.406100\n",
      "holiday      -0.068348\n",
      "weekday       0.067443\n",
      "workingday    0.061156\n",
      "weathersit   -0.297391\n",
      "temp          0.627494\n",
      "atemp         0.631066\n",
      "hum          -0.100659\n",
      "windspeed    -0.234545\n",
      "Name: cnt, dtype: float64\n",
      "\n",
      "Attributes related to cnt based on Pearson correlation (threshold > 0.3):\n",
      "['instant', 'season', 'temp', 'atemp']\n"
     ]
    }
   ],
   "source": [
    "# List of numerical features (including the target variable 'cnt')\n",
    "numerical_features = ['instant', 'season', 'holiday', 'weekday', 'workingday', \n",
    "                      'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'cnt']\n",
    "\n",
    "# Calculate Pearson correlation with 'cnt'\n",
    "pearson_corr = df[numerical_features].corr()['cnt'].drop('cnt')\n",
    "print(\"Pearson Correlation with cnt:\\n\", pearson_corr)\n",
    "\n",
    "# Determine whether each attribute is related to 'cnt'\n",
    "threshold = 0.3  # You can adjust this threshold based on your criteria\n",
    "related_features = pearson_corr[abs(pearson_corr) > threshold].index.tolist()\n",
    "\n",
    "print(\"\\nAttributes related to cnt based on Pearson correlation (threshold > 0.3):\")\n",
    "print(related_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db81dd0-aced-477a-8877-9008ba6a9771",
   "metadata": {},
   "source": [
    "## Step:3 Splitting the Data into Training and Testing Sets\n",
    "- **Feature Matrix (X):** Excludes the target variable `cnt`.\n",
    "- **Target Variable (y):** The `cnt` column, representing the total rental bike usage.\n",
    "- **Train-Test Split:** The data is split into training and testing sets with an 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0a0a801-ac59-4128-b637-2b230eec2d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (584, 13)\n",
      "X_test shape: (147, 13)\n",
      "y_train shape: (584,)\n",
      "y_test shape: (147,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the target variable 'y' and features 'X'\n",
    "y = df['cnt']\n",
    "\n",
    "# Exclude 'cnt' from the features to create X\n",
    "X = df.drop('cnt', axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shape of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e9076-ae30-4372-b53d-afdf94e58c51",
   "metadata": {},
   "source": [
    "## 3.1 Simple Linear Regression\n",
    "- **Model:** Simple Linear Regression using the feature `atemp` (feeling temperature).\n",
    "- **Training:** The model is trained on `X_train[['atemp']]`.\n",
    "- **Evaluation:** The model's performance is evaluated using Mean Squared Error (MSE) and R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c69748-8d97-480e-bdd5-c4cac928669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Linear Regression MSE: 2359187.322761967\n",
      "Simple Linear Regression R²: 0.4116567138444909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Simple Linear Regression using 'atemp'\n",
    "X_simple = X[['atemp']]\n",
    "simple_model = LinearRegression()\n",
    "simple_model.fit(X_train[['atemp']], y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_simple = simple_model.predict(X_test[['atemp']])\n",
    "\n",
    "# Evaluate the model\n",
    "mse_simple = mean_squared_error(y_test, y_pred_simple)\n",
    "r2_simple = r2_score(y_test, y_pred_simple)\n",
    "print(f\"Simple Linear Regression MSE: {mse_simple}\")\n",
    "print(f\"Simple Linear Regression R²: {r2_simple}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59348e3c-fbaf-463e-82fc-fc73a76f5a43",
   "metadata": {},
   "source": [
    "## 3.2 Multi Linear Regression\n",
    "- **Model:** Multi Linear Regression using all related features identified by Pearson correlation.\n",
    "- **Training:** The model is trained on the selected related features.\n",
    "- **Evaluation:** The model's performance is evaluated using MSE and R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf11cc37-11af-4b15-9b82-0461d5a1a1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Linear Regression MSE: 1209657.3093978039\n",
      "Multi Linear Regression R²: 0.698330967758874\n"
     ]
    }
   ],
   "source": [
    "# Multi Linear Regression using all related features\n",
    "multi_model = LinearRegression()\n",
    "multi_model.fit(X_train[related_features], y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_multi = multi_model.predict(X_test[related_features])\n",
    "\n",
    "# Evaluate the model\n",
    "mse_multi = mean_squared_error(y_test, y_pred_multi)\n",
    "r2_multi = r2_score(y_test, y_pred_multi)\n",
    "print(f\"Multi Linear Regression MSE: {mse_multi}\")\n",
    "print(f\"Multi Linear Regression R²: {r2_multi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b76c1a5-b861-4503-97e3-d8022ddf2712",
   "metadata": {},
   "source": [
    "## 3.3 Simple Polynomial Regression\n",
    "- **Model:** Polynomial Regression `(degree 2)` using the feature `atemp`.\n",
    "- **Training:** The model is trained on the polynomial features derived from `atemp`.\n",
    "- **Evaluation:** The model's performance is evaluated using MSE and R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef24e2c6-4799-42b2-87cb-a2d9d8317021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Polynomial Regression MSE: 2386473.376001215\n",
      "Simple Polynomial Regression R²: 0.4048520120414143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Polynomial Regression (degree 2)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X_train[['atemp']])\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_poly, y_train)\n",
    "\n",
    "# Predictions\n",
    "X_test_poly = poly.transform(X_test[['atemp']])\n",
    "y_pred_poly = poly_model.predict(X_test_poly)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_poly = mean_squared_error(y_test, y_pred_poly)\n",
    "r2_poly = r2_score(y_test, y_pred_poly)\n",
    "print(f\"Simple Polynomial Regression MSE: {mse_poly}\")\n",
    "print(f\"Simple Polynomial Regression R²: {r2_poly}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974e010-5825-41c7-9635-af06571abc3d",
   "metadata": {},
   "source": [
    "## 3.4 Multi Polynomial Regression\n",
    "- **Model:** Polynomial Regression `(degree 2)` using all related features.\n",
    "- **Training:** The model is trained on the polynomial features derived from the related features.\n",
    "- **Evaluation:** The model's performance is evaluated using MSE and R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f01d13b6-644a-46c3-817b-7a673d6d0afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Polynomial Regression MSE: 1089210.9668534503\n",
      "Multi Polynomial Regression R²: 0.7283683438901576\n"
     ]
    }
   ],
   "source": [
    "# Polynomial Regression with multiple features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_multi_poly = poly.fit_transform(X_train[related_features])\n",
    "multi_poly_model = LinearRegression()\n",
    "multi_poly_model.fit(X_multi_poly, y_train)\n",
    "\n",
    "# Predictions\n",
    "X_test_multi_poly = poly.transform(X_test[related_features])\n",
    "y_pred_multi_poly = multi_poly_model.predict(X_test_multi_poly)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_multi_poly = mean_squared_error(y_test, y_pred_multi_poly)\n",
    "r2_multi_poly = r2_score(y_test, y_pred_multi_poly)\n",
    "print(f\"Multi Polynomial Regression MSE: {mse_multi_poly}\")\n",
    "print(f\"Multi Polynomial Regression R²: {r2_multi_poly}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5153fbf0-323d-4639-b546-43f8928c2fb7",
   "metadata": {},
   "source": [
    "## 3.5 Lasso Regression\n",
    "- **Model:** Lasso Regression with `alpha=0.1` using all related features.\n",
    "- **Training:** The model is trained on the related features with Lasso regularization applied.\n",
    "- **Evaluation:** The model's performance is evaluated using MSE and R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d598883c-793e-46c7-8cfe-5b08832cd778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression MSE: 1209734.492870611\n",
      "Lasso Regression R²: 0.6983117194450204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train[related_features], y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lasso = lasso_model.predict(X_test[related_features])\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "print(f\"Lasso Regression MSE: {mse_lasso}\")\n",
    "print(f\"Lasso Regression R²: {r2_lasso}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042037aa-4fc0-4095-88ea-6748cf0ae69a",
   "metadata": {},
   "source": [
    "## 3.6 Ridge Regression\n",
    "- **Model:** Ridge Regression with `alpha=0.1` using all related features.\n",
    "- **Training:** The model is trained on the related features with Ridge regularization applied.\n",
    "- **Evaluation:** The model's performance is evaluated using MSE and R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26c7c92-d5e0-4bb2-b23e-330155d90677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression MSE: 1211100.30194647\n",
      "Ridge Regression R²: 0.6979711086795253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_model = Ridge(alpha=0.1)\n",
    "ridge_model.fit(X_train[related_features], y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_ridge = ridge_model.predict(X_test[related_features])\n",
    "\n",
    "# Evaluate the model\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "print(f\"Ridge Regression MSE: {mse_ridge}\")\n",
    "print(f\"Ridge Regression R²: {r2_ridge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5608bb-e9f8-4d33-9f59-cafde0206682",
   "metadata": {},
   "source": [
    "## 3.7 Decision Tree Regressor\n",
    "- **Model:** Decision Tree Regressor using all related features.\n",
    "- **Training:** The model is trained on the related features.\n",
    "- **Evaluation:** The model's performance is evaluated using MSE and R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f359453-e4b8-48ba-be2b-100f29d33221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor MSE: 1106578.2653061224\n",
      "Decision Tree Regressor R²: 0.7240372196319422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train[related_features], y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_tree = tree_model.predict(X_test[related_features])\n",
    "\n",
    "# Evaluate the model\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "print(f\"Decision Tree Regressor MSE: {mse_tree}\")\n",
    "print(f\"Decision Tree Regressor R²: {r2_tree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5512e1d4-b083-4576-8f94-c29a273c3367",
   "metadata": {},
   "source": [
    "## 3.8 K-Nearest Neighbors (KNN) Regressor\n",
    "- **Model:** KNN Regressor with `n_neighbors=5` using all related features.\n",
    "- **Training:** The model is trained on the related features.\n",
    "- **Evaluation:** The model's performance is evaluated using MSE and R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914bbc7c-1912-455c-8faa-ac035a2fc6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regressor MSE: 836722.388027211\n",
      "KNN Regressor R²: 0.7913349251150229\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train[related_features], y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_knn = knn_model.predict(X_test[related_features])\n",
    "\n",
    "# Evaluate the model\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "print(f\"KNN Regressor MSE: {mse_knn}\")\n",
    "print(f\"KNN Regressor R²: {r2_knn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb2a1a-a1f7-46be-a9b4-b653ee63be61",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "## Performance Summary: \n",
    "- We compared the performance of various regression models using MSE and R² scores.\n",
    "- **Best Model:** Among the models tested, the model with the `highest R²` and `lowest MSE` is identified as the `best-performing model` for predicting bike rental usage.\n",
    "\n",
    "- **Based on the results of the models, here's the comparison:**\n",
    "\n",
    "### 1. Simple Linear Regression\n",
    "- **MSE: 2,359,187.32**\n",
    "- **R²: 0.4117**\n",
    "\n",
    "### 2. Multi Linear Regression\n",
    "- **MSE: 1,209,657.31**\n",
    "- **R²: 0.6983**\n",
    "\n",
    "### 3. Simple Polynomial Regression\n",
    "- **MSE: 2,386,473.38**\n",
    "- **R²: 0.4049**\n",
    "\n",
    "### 4. Multi Polynomial Regression\n",
    "- **MSE: 1,089,210.97**\n",
    "- **R²: 0.7284**\n",
    "\n",
    "### 5. Lasso Regression\n",
    "- **MSE: 1,209,734.49**\n",
    "- **R²: 0.6983**\n",
    "\n",
    "### 6. Ridge Regression\n",
    "- **MSE: 1,211,100.30**\n",
    "- **R²: 0.6980**\n",
    "\n",
    "### 7. Decision Tree Regressor\n",
    "- **MSE: 1,106,578.27**\n",
    "- **R²: 0.7240**\n",
    "\n",
    "### 8. KNN Regressor\n",
    "- **MSE: 836,722.39**\n",
    "- **R²: 0.7913**\n",
    "\n",
    "## Best Model\n",
    "- **`KNN Regressor`** has the `lowest MSE (836,722.39)` and the `highest R² score (0.7913)`, indicating it is the `best-performing model` among the ones tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9e6116-0ccb-4a3a-aef6-6ef4db9e9abf",
   "metadata": {},
   "source": [
    "# ALTERNATE APPROACH \n",
    "\n",
    "### Making the Function to Evaluate the every Regression Models and printing the BEST Fit Model's R² and MSE Values.\n",
    "### But the only constraint is here we need to make the Preprocessor to handle both numeric and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f7b578-8053-4df2-9542-89ce06efd5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Linear Regression MSE: 642306.02, R²: 0.8398\n",
      "Multi Linear Regression MSE: 642306.02, R²: 0.8398\n",
      "Simple Polynomial Regression MSE: 1127402.23, R²: 0.7188\n",
      "Multi Polynomial Regression MSE: 371743872.03, R²: -91.7069\n",
      "Lasso Regression MSE: 644793.40, R²: 0.8392\n",
      "Ridge Regression MSE: 649867.35, R²: 0.8379\n",
      "Decision Tree Regressor MSE: 696271.07, R²: 0.8264\n",
      "KNN Regressor MSE: 899537.94, R²: 0.7757\n",
      "\n",
      "Best Model:\n",
      "Simple Linear Regression with R²: 0.8398 and MSE: 642306.02\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"day.csv\")\n",
    "\n",
    "# Drop 'registered' and 'casual' from the DataFrame\n",
    "df = df.drop(['registered', 'casual'], axis=1)\n",
    "\n",
    "# Extract date-related features if necessary\n",
    "df['year'] = pd.to_datetime(df['dteday']).dt.year\n",
    "df['month'] = pd.to_datetime(df['dteday']).dt.month\n",
    "df['day'] = pd.to_datetime(df['dteday']).dt.day\n",
    "\n",
    "# Drop the original date column\n",
    "df = df.drop('dteday', axis=1)\n",
    "\n",
    "# Define the target variable 'y' and features 'X'\n",
    "y = df['cnt']\n",
    "X = df.drop('cnt', axis=1)\n",
    "\n",
    "# One-hot encode categorical variables if any (e.g., 'season', 'weathersit')\n",
    "categorical_features = ['season', 'weathersit']\n",
    "numerical_features = X.columns.difference(categorical_features)\n",
    "\n",
    "# Create a preprocessor to handle both numeric and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Function to evaluate and compare different regression models\n",
    "def evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    models = {\n",
    "        \"Simple Linear Regression\": Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', LinearRegression())\n",
    "        ]),\n",
    "        \"Multi Linear Regression\": Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', LinearRegression())\n",
    "        ]),\n",
    "        \"Simple Polynomial Regression\": Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('poly', PolynomialFeatures(degree=2)),\n",
    "            ('model', LinearRegression())\n",
    "        ]),\n",
    "        \"Multi Polynomial Regression\": Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('poly', PolynomialFeatures(degree=3)),\n",
    "            ('model', LinearRegression())\n",
    "        ]),\n",
    "        \"Lasso Regression\": Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', Lasso())\n",
    "        ]),\n",
    "        \"Ridge Regression\": Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', Ridge())\n",
    "        ]),\n",
    "        \"Decision Tree Regressor\": Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', DecisionTreeRegressor())\n",
    "        ]),\n",
    "        \"KNN Regressor\": Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', KNeighborsRegressor())\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        results.append((name, mse, r2))\n",
    "\n",
    "    # Find the model with the best R² score\n",
    "    best_model = max(results, key=lambda item: item[2])\n",
    "    \n",
    "    # Print all results\n",
    "    for result in results:\n",
    "        print(f\"{result[0]} MSE: {result[1]:.2f}, R²: {result[2]:.4f}\")\n",
    "    \n",
    "    print(\"\\nBest Model:\")\n",
    "    print(f\"{best_model[0]} with R²: {best_model[2]:.4f} and MSE: {best_model[1]:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Evaluate models and get the best one\n",
    "best_model = evaluate_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efff683-757a-4955-9c90-c673afd31f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
